---
title: "Media to Video"
api: "POST /api/v1/task/submit"
description: "Jimeng / Seedance Media-to-Video — Generate videos from images, videos, and audio"
---

Generate videos from reference materials including images, videos, and audio. The generation mode is automatically selected based on the number and type of materials.

### Supported Material Types

| Type | Formats | Usage | Supported Models |
|------|---------|-------|------------------|
| Image | `.jpg`, `.jpeg`, `.png`, `.webp`, `.gif`, `.bmp` | First/last frame or reference | All models |
| Video | `.mp4`, `.mov`, `.m4v` | Multimodal reference | `seedance-*` only |
| Audio | `.mp3`, `.wav` | Multimodal reference (max 15s) | `seedance-*` only |

<Warning>
  **Video and audio materials are only supported by Seedance models** (`seedance-2.0`, `seedance-2.0-fast`). The `jimeng-video-*` models only support up to 2 images (first/last frame mode).
</Warning>

<ParamField body="model" type="string" required>
  Model name, e.g. `seedance-2.0`, `seedance-2.0-fast`, `jimeng-video-3.5-pro`.
</ParamField>

<ParamField body="callBackUrl" type="string">
  Webhook callback URL.
</ParamField>

<ParamField body="input" type="object" required>
  <Expandable title="properties" defaultOpen>
    <ParamField body="prompt" type="string" required>
      Prompt. Use `@1`, `@2`, `@3` to reference materials by position (supports `@图1` and `@image1` as well).
    </ParamField>
    <ParamField body="mediaUrls" type="string[]">
      List of material URLs. Supports mixed images, videos, and audio. Material type is auto-detected by file extension. The number and type of materials determine the generation mode (see below).
    </ParamField>
    <ParamField body="imageUrls" type="string[]">
      List of reference image URLs. Backward compatible — equivalent to `mediaUrls` with images only.

      > If both `mediaUrls` and `imageUrls` are provided, `mediaUrls` takes precedence.
    </ParamField>
    <ParamField body="ratio" type="string">
      Video aspect ratio. Options: `1:1`, `4:3`, `3:4`, `16:9`, `9:16`.
    </ParamField>
    <ParamField body="resolution" type="string">
      Video resolution. Options: `480p`, `720p`, `1080p`.
    </ParamField>
    <ParamField body="duration" type="integer">
      Video duration in seconds. Seedance models support `4`–`15` seconds; other models support `5` or `10`.
    </ParamField>
    <ParamField body="fallback" type="boolean" default="true">
      Whether to automatically fall back to `jimeng-video-3.5-pro` when a Seedance model fails. Defaults to `true`. Set to `false` to disable fallback and return the original error directly. Only applies to Seedance models; ignored by other models. Note: multimodal requests (containing video/audio materials, >2 images, or `@1`/`@2` placeholder references) never fall back regardless of this setting.
    </ParamField>
  </Expandable>
</ParamField>

<RequestExample>
```bash First Frame (1 image)
curl --request POST \
  --url https://api.maxapi.io/api/v1/task/submit \
  --header 'Authorization: Bearer <token>' \
  --header 'Content-Type: application/json' \
  --data '{
  "model": "seedance-2.0",
  "input": {
    "prompt": "Blow out candles",
    "mediaUrls": ["https://example.com/photo.jpg"]
  }
}'
```

```bash Multimodal (image + audio)
curl --request POST \
  --url https://api.maxapi.io/api/v1/task/submit \
  --header 'Authorization: Bearer <token>' \
  --header 'Content-Type: application/json' \
  --data '{
  "model": "seedance-2.0",
  "input": {
    "prompt": "@1 dances to the rhythm of @2",
    "mediaUrls": [
      "https://example.com/dancer.jpg",
      "https://example.com/music.mp3"
    ]
  }
}'
```
</RequestExample>

<ResponseExample>
```json 200 Submitted successfully
{
  "code": 0,
  "msg": "ok",
  "data": {
    "taskId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890"
  }
}
```
</ResponseExample>

---

## Generation Modes

The generation mode is automatically selected based on the number and type of materials:

| Condition | Mode | Description | Supported Models |
|-----------|------|-------------|------------------|
| 1 image | First Frame | Image becomes the first frame | All models |
| 2 images | First & Last Frame | Two images become the start and end frames | All models |
| 3+ images | Multi-Image Reference | Reference multiple images via `@1`, `@2`, `@3` | `seedance-*` only |
| Contains video or audio | Multimodal Reference | Mix images, videos, and audio as references | `seedance-*` only |

### 1 Image — First Frame Mode

The image is used as the first frame of the video, and subsequent animation is generated based on the prompt.

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "Blow out candles",
    "mediaUrls": ["https://assets.movart.ai/landingpage/dog.webp"]
  }
}
```

### 2 Images — First & Last Frame Mode

The first image serves as the video's first frame, the second image as the last frame, and the AI automatically generates the transition animation in between.

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "Transform",
    "mediaUrls": [
      "https://assets.movart.ai/3D-Cartoon.jpg",
      "https://assets.movart.ai/landingpage/dog.webp"
    ]
  }
}
```

### 3+ Images — Multi-Image Reference Mode (Seedance only)

Use `@1`, `@2`, `@3` in the prompt to reference the corresponding materials by position.

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "@1 and @2 are chatting, @3 is watching",
    "mediaUrls": [
      "https://example.com/person-a.jpg",
      "https://example.com/person-b.jpg",
      "https://example.com/person-c.jpg"
    ]
  }
}
```

### Multimodal Reference Mode (Seedance only)

When materials contain videos or audio (or any mix of image + video + audio), the multimodal reference mode is automatically activated. Use `@1`, `@2`, etc. to reference each material by position.

<Note>Audio files must be **15 seconds or shorter**. Longer audio will be rejected.</Note>

**Image + Audio** — generate a video where the character moves to the rhythm of the music:

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "@1 dances to the rhythm of @2",
    "mediaUrls": [
      "https://example.com/dancer.jpg",
      "https://example.com/music.mp3"
    ],
    "ratio": "16:9",
    "duration": 8
  }
}
```

**Image + Video** — use a video as motion reference alongside an image:

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "@1 performs the action shown in @2",
    "mediaUrls": [
      "https://example.com/character.jpg",
      "https://example.com/reference-motion.mp4"
    ]
  }
}
```

**Multiple types mixed** — combine images, videos, and audio freely:

```json
{
  "model": "seedance-2.0",
  "input": {
    "prompt": "@1 and @2 dance together to @3",
    "mediaUrls": [
      "https://example.com/person-a.jpg",
      "https://example.com/person-b.jpg",
      "https://example.com/bgm.mp3"
    ],
    "duration": 10
  }
}
```

---

## Query Result

Retrieve the generation result via the [Query Task](/api-reference/query-task) endpoint or Webhook:

```json
{
  "code": 0,
  "msg": "ok",
  "data": {
    "taskId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "status": "SUCCESS",
    "input": {
      "model": "seedance-2.0",
      "prompt": "@1 dances to the rhythm of @2",
      "mediaUrls": [
        "https://example.com/dancer.jpg",
        "https://example.com/music.mp3"
      ]
    },
    "result": {
      "type": "video",
      "urls": [
        "https://v9-dreamnia.jimeng.com/video/tos/cn/video_example.mp4"
      ]
    },
    "created_at": "2026-02-10T23:00:00.000000Z",
    "updated_at": "2026-02-10T23:03:25.000000Z"
  }
}
```
